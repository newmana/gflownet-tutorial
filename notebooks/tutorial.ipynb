{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Generative Flow Network Demo\n",
    "From https://colab.research.google.com/drive/1fUMwgu2OhYpQagpzU5mhe9_Esib3Q2VR\n"
   ],
   "id": "f78bc92c4b823720"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as matplotlib_pyplot\n",
    "import numpy as numpy\n",
    "import torch\n",
    "import tqdm\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "# Add the project root directory to Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "import gflownet as gflownet"
   ],
   "id": "8c08801e5eba6378",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_faces(faces):\n",
    "    f, ax = matplotlib_pyplot.subplots(1, len(faces))\n",
    "    for i in range(len(faces)):\n",
    "        if len(faces) > 1:\n",
    "            matplotlib_pyplot.sca(ax[i])\n",
    "        gflownet.Face.draw_face(faces[i])\n",
    "\n",
    "smiling_face = gflownet.Face(['smile', 'left_eb_down', 'right_eb_down'])\n",
    "frowning_face = gflownet.Face(['frown', 'left_eb_up', 'right_eb_up'])\n",
    "plot_faces([gflownet.Face(['left_eb_up', 'right_eb_up']), gflownet.Face(['frown']), gflownet.Face(['smile'])])\n",
    "plot_faces([gflownet.Face(['left_eb_up', 'left_eb_down']), gflownet.Face(['right_eb_up', 'right_eb_down']),\n",
    "            gflownet.Face(['left_eb_up', 'left_eb_down', 'right_eb_up', 'right_eb_down']),\n",
    "            gflownet.Face(['smile', 'frown'])])\n",
    "plot_faces([frowning_face, smiling_face])"
   ],
   "id": "ff575fa92ad2c888",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "enumerated_states, transitions = gflownet.Face.enumerate_states_transitions(gflownet.Face.sorted_keys)\n",
    "unique_states = []\n",
    "for face in enumerated_states:\n",
    "    if set(face.patches) not in [set(u.patches) for u in unique_states]:\n",
    "        unique_states.append(face)"
   ],
   "id": "a0b7d592ec97a676",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def face_hash(face):\n",
    "    return tuple([i in face for i in gflownet.Face.sorted_keys])"
   ],
   "id": "b067e36e2a66558e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lens = [len([i for i in unique_states if len(i) == j]) for j in range(4)]\n",
    "levels = [sorted([i for i in unique_states if len(i) == j]) for j in range(4)]\n",
    "f = matplotlib_pyplot.figure(figsize=(8, 8))\n",
    "face2pos = {}\n",
    "for i, (level, L) in enumerate(zip(levels, lens)):\n",
    "    for j, face in enumerate(level):\n",
    "        ax = f.add_axes([j / L, i / 4, 1 / L, 1 / 6])\n",
    "        face.draw_face()\n",
    "        face2pos[face_hash(face)] = (j / L + 0.5 / L, i / 4)\n",
    "ax = f.add_axes([0, 0, 1, 1])\n",
    "matplotlib_pyplot.sca(ax)\n",
    "matplotlib_pyplot.gca().set_facecolor((0, 0, 0, 0))\n",
    "matplotlib_pyplot.xlim(0, 1)\n",
    "matplotlib_pyplot.ylim(0, 1)\n",
    "for a, b in transitions[1:]:\n",
    "    pa, pb = face2pos[face_hash(a)], face2pos[face_hash(b)]\n",
    "    if not len(b): continue\n",
    "    lb = int(pb[1] * 4)\n",
    "    la = int(pa[1] * 4)\n",
    "    ws = [1 / 6, 1 / 6, 0.13, 0.11]\n",
    "    matplotlib_pyplot.arrow(pa[0], pa[1] + ws[la], pb[0] - pa[0], pb[1] - pa[1] - ws[lb], head_width=0.01, width=0.003,\n",
    "                            ec=(0., 0.5, 0), fc=(0, 0, 0),\n",
    "                            length_includes_head=True)\n",
    "    matplotlib_pyplot.axis('off')"
   ],
   "id": "4463cf6168a14253",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def face_parents(state):\n",
    "    parent_states = []  # states that are parents of state\n",
    "    parent_actions = []  # actions that lead from those parents to state\n",
    "    for face_part in state:\n",
    "        # For each face part, there is a parent without that part\n",
    "        parent_states.append([i for i in state if i != face_part])\n",
    "        # The action to get there is the corresponding index of that face part\n",
    "        parent_actions.append(gflownet.Face.sorted_keys.index(face_part))\n",
    "    return parent_states, parent_actions"
   ],
   "id": "96a03dfb514e919c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Flow Matching\n",
    "https://arxiv.org/abs/2106.04399"
   ],
   "id": "1441d296cda541e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Instantiate model and optimizer\n",
    "F_sa = gflownet.FlowModel(512)\n",
    "opt = torch.optim.Adam(F_sa.parameters(), 3e-4)\n",
    "\n",
    "# Let's keep track of the losses and the faces we sample\n",
    "losses = []\n",
    "sampled_faces = []\n",
    "# To not complicate the code, I'll just accumulate losses here and take a\n",
    "# gradient step every `update_freq` episode.\n",
    "minibatch_loss = 0\n",
    "update_freq = 4\n",
    "for episode in tqdm.tqdm(range(50000), ncols=40):\n",
    "    # Each episode starts with an \"empty state\"\n",
    "    state = []\n",
    "    # Predict F(s, a)\n",
    "    edge_flow_prediction = F_sa(gflownet.Face(state).face_to_tensor())\n",
    "    for t in range(3):\n",
    "        # The policy is just normalizing, and gives us the probability of each action\n",
    "        policy = edge_flow_prediction / edge_flow_prediction.sum()\n",
    "        # Sample the action\n",
    "        action = Categorical(probs=policy).sample()\n",
    "        # \"Go\" to the next state\n",
    "        new_state = state + [gflownet.Face.sorted_keys[action]]\n",
    "\n",
    "        # Now we want to compute the loss, we'll first enumerate the parents\n",
    "        parent_states, parent_actions = face_parents(new_state)\n",
    "        # And compute the edge flows F(s, a) of each parent\n",
    "        px = torch.stack([gflownet.Face(p).face_to_tensor() for p in parent_states])\n",
    "        pa = torch.tensor(parent_actions).long()\n",
    "        parent_edge_flow_preds = F_sa(px)[torch.arange(len(parent_states)), pa]\n",
    "        # Now we need to compute the reward and F(s, a) of the current state,\n",
    "        # which is currently `new_state`\n",
    "        if t == 2:\n",
    "            # If we've built a complete face, we're done, so the reward is > 0\n",
    "            # (unless the face is invalid)\n",
    "            reward = gflownet.Face(new_state).face_reward()\n",
    "            # and since there are no children to this state F(s,a) = 0 \\forall a\n",
    "            edge_flow_prediction = torch.zeros(6)\n",
    "        else:\n",
    "            # Otherwise we keep going, and compute F(s, a)\n",
    "            reward = 0\n",
    "            edge_flow_prediction = F_sa(gflownet.Face(new_state).face_to_tensor())\n",
    "\n",
    "        # The loss as per the equation above\n",
    "        flow_mismatch = (parent_edge_flow_preds.sum() - edge_flow_prediction.sum() - reward).pow(2)\n",
    "        minibatch_loss += flow_mismatch  # Accumulate\n",
    "        # Continue iterating\n",
    "        state = new_state\n",
    "\n",
    "    # We're done with the episode, add the face to the list, and if we are at an\n",
    "    # update episode, take a gradient step.\n",
    "    sampled_faces.append(gflownet.Face(state))\n",
    "    if episode % update_freq == 0:\n",
    "        losses.append(minibatch_loss.item())\n",
    "        minibatch_loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        minibatch_loss = 0"
   ],
   "id": "bd396abc4fad6003",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "matplotlib_pyplot.figure(figsize=(10, 3))\n",
    "matplotlib_pyplot.plot(losses)\n",
    "matplotlib_pyplot.yscale('log')"
   ],
   "id": "1fcbda625be37f37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "f, ax = matplotlib_pyplot.subplots(8, 8, figsize=(4, 4))\n",
    "print('Ratio of faces with a smile:', sum(['smile' in i.patches for i in sampled_faces[-128:]]) / 128)\n",
    "print('Ratio of valid faces:', sum([i.face_reward() > 0 for i in sampled_faces[-128:]]) / 128)\n",
    "for i, face in enumerate(sampled_faces[-64:]):\n",
    "    matplotlib_pyplot.sca(ax[i // 8, i % 8])\n",
    "    face.draw_face()"
   ],
   "id": "d6a6d25dca1d332c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lens = [len([i for i in unique_states if len(i) == j]) for j in range(4)]\n",
    "levels = [sorted([i for i in unique_states if len(i) == j]) for j in range(4)]\n",
    "f = matplotlib_pyplot.figure(figsize=(8, 8))\n",
    "face2pos = {}\n",
    "for i, (level, L) in enumerate(zip(levels, lens)):\n",
    "    for j, face in enumerate(level):\n",
    "        ax = f.add_axes([j / L, i / 4, 1 / L, 1 / 6])\n",
    "        gflownet.Face(face).draw_face()\n",
    "        face2pos[face_hash(face)] = (j / L + 0.5 / L, i / 4)\n",
    "        Fstate = F_sa(torch.tensor(face_hash(face)).float())\n",
    "        #print(face, Fstate.data)\n",
    "ax = f.add_axes([0, 0, 1, 1])\n",
    "matplotlib_pyplot.sca(ax)\n",
    "matplotlib_pyplot.gca().set_facecolor((0, 0, 0, 0))\n",
    "matplotlib_pyplot.xlim(0, 1)\n",
    "matplotlib_pyplot.ylim(0, 1)\n",
    "for a, b in transitions[1:]:\n",
    "    if not len(b):\n",
    "        continue\n",
    "    pa, pb = face2pos[face_hash(a)], face2pos[face_hash(b)]\n",
    "    lb = int(pb[1] * 4)\n",
    "    Fstate = F_sa(torch.tensor(face_hash(a)).float())\n",
    "    Fa = Fstate[gflownet.Face.sorted_keys.index([i for i in b if i not in a][0])].item()\n",
    "    c = cm.brg(Fa / 3)\n",
    "    lb = int(pb[1] * 4)\n",
    "    la = int(pa[1] * 4)\n",
    "    ws = [1 / 6, 1 / 6, 0.13, 0.11]\n",
    "    matplotlib_pyplot.arrow(pa[0], pa[1] + ws[la], pb[0] - pa[0], pb[1] - pa[1] - ws[lb], head_width=0.01, width=0.003,\n",
    "                            ec=c, fc=c,\n",
    "                            length_includes_head=True)\n",
    "    matplotlib_pyplot.axis('off')\n",
    "ax = f.add_axes([1, 0.2, 0.05, 0.6])\n",
    "matplotlib_pyplot.sca(ax)\n",
    "f.colorbar(cm.ScalarMappable(norm=cm.colors.Normalize(vmin=0, vmax=3), cmap=cm.brg), cax=ax, label='Edge Flow');"
   ],
   "id": "daaee368adf6d2eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "F_sa(gflownet.Face([]).face_to_tensor()).sum()",
   "id": "445fee643e0d71bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Instantiate model and optimizer\n",
    "model = gflownet.TBModel(512)\n",
    "opt = torch.optim.Adam(model.parameters(), 3e-4)\n",
    "\n",
    "# Let's keep track of the losses and the faces we sample\n",
    "tb_losses = []\n",
    "tb_sampled_faces = []\n",
    "# To not complicate the code, I'll just accumulate losses here and take a\n",
    "# gradient step every `update_freq` episode.\n",
    "minibatch_loss = 0\n",
    "update_freq = 2\n",
    "\n",
    "logZs = []\n",
    "for episode in tqdm.tqdm(range(50000), ncols=40):\n",
    "    # Each episode starts with an \"empty state\"\n",
    "    state = []\n",
    "    # Predict P_F, P_B\n",
    "    P_F_s, P_B_s = model(gflownet.Face(state).face_to_tensor())\n",
    "    total_P_F = 0\n",
    "    total_P_B = 0\n",
    "    for t in range(3):\n",
    "        # Here P_F is logits, so we want the Categorical to compute the softmax for us\n",
    "        cat = Categorical(logits=P_F_s)\n",
    "        action = cat.sample()\n",
    "        # \"Go\" to the next state\n",
    "        new_state = state + [gflownet.Face.sorted_keys[action]]\n",
    "        # Accumulate the P_F sum\n",
    "        total_P_F += cat.log_prob(action)\n",
    "\n",
    "        if t == 2:\n",
    "            # If we've built a complete face, we're done, so the reward is > 0\n",
    "            # (unless the face is invalid)\n",
    "            reward = torch.tensor(gflownet.Face(new_state).face_reward()).float()\n",
    "        # We recompute P_F and P_B for new_state\n",
    "        P_F_s, P_B_s = model(gflownet.Face(new_state).face_to_tensor())\n",
    "        # Here we accumulate P_B, going backwards from `new_state`. We're also just\n",
    "        # going to use opposite semantics for the backward policy. I.e., for P_F action\n",
    "        # `i` just added the face part `i`, for P_B we'll assume action `i` removes\n",
    "        # face part `i`, this way we can just keep the same indices.\n",
    "        total_P_B += Categorical(logits=P_B_s).log_prob(action)\n",
    "\n",
    "        # Continue iterating\n",
    "        state = new_state\n",
    "\n",
    "    # We're done with the trajectory, let's compute its loss. Since the reward can\n",
    "    # sometimes be zero, instead of log(0) we'll clip the log-reward to -20.\n",
    "    loss = (model.logZ + total_P_F - torch.log(reward).clip(-20) - total_P_B).pow(2)\n",
    "    minibatch_loss += loss\n",
    "\n",
    "    # Add the face to the list, and if we are at an\n",
    "    # update episode, take a gradient step.\n",
    "    tb_sampled_faces.append(state)\n",
    "    if episode % update_freq == 0:\n",
    "        tb_losses.append(minibatch_loss.item())\n",
    "        minibatch_loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        minibatch_loss = 0\n",
    "        logZs.append(model.logZ.item())"
   ],
   "id": "e417f9774edb177f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "f, ax = matplotlib_pyplot.subplots(2, 1, figsize=(10, 6))\n",
    "matplotlib_pyplot.sca(ax[0])\n",
    "matplotlib_pyplot.plot(tb_losses)\n",
    "matplotlib_pyplot.yscale('log')\n",
    "matplotlib_pyplot.ylabel('loss')\n",
    "matplotlib_pyplot.sca(ax[1])\n",
    "matplotlib_pyplot.plot(numpy.exp(logZs))\n",
    "matplotlib_pyplot.ylabel('estimated Z');"
   ],
   "id": "2b022d401c911a3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "f, ax = matplotlib_pyplot.subplots(8, 8, figsize=(4, 4))\n",
    "print('Ratio of faces with a smile:', sum(['smile' in i for i in tb_sampled_faces[-128:]]) / 128)\n",
    "print('Ratio of valid faces:', sum([gflownet.Face(i).face_reward() > 0 for i in tb_sampled_faces[-128:]]) / 128)\n",
    "for i, face in enumerate(tb_sampled_faces[-64:]):\n",
    "    matplotlib_pyplot.sca(ax[i // 8, i % 8])\n",
    "    gflownet.Face(face).draw_face()"
   ],
   "id": "cda5d473a08ffcf7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.logZ.exp()",
   "id": "112ac6a825807c2e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
